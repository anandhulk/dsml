{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gopika-C/S3-Data-Science-Lab/blob/main/NLP_CHUNKS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7a74f40",
      "metadata": {
        "id": "b7a74f40"
      },
      "source": [
        "Chunking\n",
        "\n",
        "Chunking is a process of extracting phrases from unstructured text. \n",
        "Instead of just simple tokens which may not represent the actual meaning of the text, its advisable to use phrases such as “South Africa” as a single word instead of ‘South’ and ‘Africa’ separate words.\n",
        "Chunking works on top of POS tagging, it uses pos-tags as input and provides chunks as output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4662be1b",
      "metadata": {
        "id": "4662be1b"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import state_union\n",
        "from nltk.tokenize import PunktSentenceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e412ca8f",
      "metadata": {
        "id": "e412ca8f"
      },
      "outputs": [],
      "source": [
        "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
        "sample_text = state_union.raw(\"2006-GWBush.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdc955c8",
      "metadata": {
        "id": "fdc955c8"
      },
      "outputs": [],
      "source": [
        "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
        "\n",
        "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17ef3645",
      "metadata": {
        "id": "17ef3645"
      },
      "outputs": [],
      "source": [
        "def process_content():\n",
        "    try:\n",
        "        for i in tokenized:\n",
        "            words = nltk.word_tokenize(i)\n",
        "            tagged = nltk.pos_tag(words)\n",
        "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
        "            chunkParser = nltk.RegexpParser(chunkGram)\n",
        "            chunked = chunkParser.parse(tagged)\n",
        "            chunked.draw()     \n",
        "\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "\n",
        "process_content()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5cf0a59",
      "metadata": {
        "id": "e5cf0a59"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e6bcce",
      "metadata": {
        "id": "70e6bcce"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}